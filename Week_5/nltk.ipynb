{
 "metadata": {
  "name": "nltk.ipynb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Natural Language ToolKit"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pip install nltk\n",
      "import nltk\n",
      "nltk.download()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk.book as b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b.text1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# another way\n",
      "moby = nltk.text.Text(nltk.corpus.gutenberg.words('melville-moby_dick.txt'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(b.text1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# haaalp\n",
      "hltk.text.Text?\n",
      "nltk.text.Text??\n",
      "help(nltk.text.Text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "txt = b.text1\n",
      "txt[:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "txt.count(\"me\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "txt.findall(\"<[A-Za-z]*><me>\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b.text3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b.text3.count(\"me\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b.text3.findall(\"<[A-Za-z]*><me>\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "title('Genesis')\n",
      "b.text3.plot(30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "title('Moby Dick')\n",
      "txt.plot(30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Collocations are expressions of multiple words which commonly co-occur\n",
      "b.text3.collocations()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b.text3.dispersion_plot([\"LORD\", \"God\", \"unto\", \"Adam\", \"Egypt\", \"seven\", \"Joseph\", \"Abraham\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# shows context around a word\n",
      "moby.concordance(\"ishmael\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# slow\n",
      "# words that that occur frequently in the same context and with a similar distribution\n",
      "moby.similar(\"ship\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# corpus of innagural addresses given by U.S. presidents\n",
      "\n",
      "inaugural = nltk.text.Text(nltk.corpus.inaugural.words())\n",
      "inaugural.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\",\"terror\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Frequency Analysis"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "In statistical machine learning approaches to NLP, the very first thing we need to do is count things - especially the unigrams that appear in the text and their relationships to each other. NLTK provides two very excellent classes to enable these frequency analyses:\n",
      "\n",
      "- FreqDist\n",
      "- ConditionalFreqDist\n",
      "\n",
      "First we will compute the following:\n",
      "\n",
      "- The count of words\n",
      "- The vocabulary (unique words)\n",
      "- The lexical diversity (the ratio of word count to vocabulary)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reuters = nltk.corpus.reuters # Corpus of news articles\n",
      "counts  = nltk.FreqDist(reuters.words())\n",
      "vocab   = len(counts.keys())\n",
      "words   = sum(counts.values())\n",
      "lexdiv  = float(words) / float(vocab)\n",
      "\n",
      "print \"Corpus has %i types and %i tokens for a lexical diversity of %0.3f\" % (vocab, words, lexdiv)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# counts tokens\n",
      "counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counts.most_common(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# hapax legomena: a word that occurs only once within a context, either in the written \n",
      "# record of an entire language, in the works of an author, or in a single text.\n",
      "\n",
      "counts.hapaxes()[0:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counts.freq('American') * 100 # percentage of the corpus for this token"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rcParams['figure.figsize'] = 20,10\n",
      "counts.plot(100, cumulative=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Processing Text"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "- sent_tokenize: \n",
      "- word_tokenize: \n",
      "- pos_tag: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = u\"Medical personnel returning to New York and New Jersey from the Ebola-riddled countries in West Africa will be automatically quarantined if they had direct contact with an infected person, officials announced Friday. New York Gov. Andrew Cuomo (D) and New Jersey Gov. Chris Christie (R) announced the decision at a joint news conference Friday at 7 World Trade Center. \u201cWe have to do more,\u201d Cuomo said. \u201cIt\u2019s too serious of a situation to leave it to the honor system of compliance.\u201d They said that public-health officials at John F. Kennedy and Newark Liberty international airports, where enhanced screening for Ebola is taking place, would make the determination on who would be quarantined. Anyone who had direct contact with an Ebola patient in Liberia, Sierra Leone or Guinea will be quarantined. In addition, anyone who traveled there but had no such contact would be actively monitored and possibly quarantined, authorities said. This news came a day after a doctor who had treated Ebola patients in Guinea was diagnosed in Manhattan, becoming the fourth person diagnosed with the virus in the United States and the first outside of Dallas. And the decision came not long after a health-care worker who had treated Ebola patients arrived at Newark, one of five airports where people traveling from West Africa to the United States are encountering the stricter screening rules.\"\n",
      "\n",
      "for sent in nltk.sent_tokenize(text): \n",
      "    print sent\n",
      "    print\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for sent in nltk.sent_tokenize(text):\n",
      "    print list(nltk.word_tokenize(sent))\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for sent in nltk.sent_tokenize(text):\n",
      "    print list(nltk.pos_tag(nltk.word_tokenize(sent)))\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Work pretty well - but trained on specific corpora. \n",
      "When working in-depth with these tools, need to train on your own corpora."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Stemming and Lemmatization"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "How do we have canonical representations of words?\n",
      "\n",
      "Stemming = get the root stem of the word\n",
      "\n",
      "- running --> run\n",
      "- flowers --> flower\n",
      "- geese --> geese\n",
      "\n",
      "Lemmatization = get canonical lemma of word from lexicon\n",
      "- women --> woman\n",
      "- foxes --> fox\n",
      "- sheep --> sheep\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# a few stemmers available\n",
      "\n",
      "from nltk.stem.snowball import SnowballStemmer\n",
      "from nltk.stem.lancaster import LancasterStemmer\n",
      "from nltk.stem.porter import PorterStemmer\n",
      "\n",
      "text = list(nltk.word_tokenize(\"The women running in the fog passed bunnies working as computer scientists.\"))\n",
      "\n",
      "snowball = SnowballStemmer('english')\n",
      "lancaster = LancasterStemmer()\n",
      "porter = PorterStemmer()\n",
      "\n",
      "for stemmer in (snowball, lancaster, porter):\n",
      "    stemmed_text = [stemmer.stem(t) for t in text]\n",
      "    print stemmed_text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lemmatize\n",
      "\n",
      "from nltk.stem.wordnet import WordNetLemmatizer\n",
      "\n",
      "lemmatizer = WordNetLemmatizer()\n",
      "lemmas = [lemmatizer.lemmatize(t) for t in text]\n",
      "print lemmas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Typical text normalization looks something like this\n",
      "\n",
      "import string\n",
      "\n",
      "## Module constants\n",
      "lemmatizer  = WordNetLemmatizer()\n",
      "stopwords   = set(nltk.corpus.stopwords.words('english'))\n",
      "punctuation = string.punctuation\n",
      "\n",
      "def normalize(text):\n",
      "    for token in nltk.word_tokenize(text):\n",
      "        token = token.lower()\n",
      "        token = lemmatizer.lemmatize(token)\n",
      "        if token not in stopwords and token not in punctuation:\n",
      "            yield token\n",
      "\n",
      "print list(normalize(\"The eagle flies at midnight.\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "POS tagging / Named Entity Recognition"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lots of tutorials online... Not going to get into this\n",
      "\n",
      "from nltk import ne_chunk, pos_tag, word_tokenize as tokenize\n",
      "\n",
      "sentence = \"the quick brown fox jumped over the lazy dog.\"\n",
      "ne_chunk(pos_tag(tokenize(sentence)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}