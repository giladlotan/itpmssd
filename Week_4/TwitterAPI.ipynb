{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Go to http://dev.twitter.com/apps/new to create an app and get values for these credentials, which you'll need to provide in place of these empty string values that are defined as placeholders.\n",
    "\n",
    "\n",
    "- See https://dev.twitter.com/docs/auth/oauth for more information on Twitter's OAuth implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pip install python-twitter -> run that command in your remote machine's terminal window to install the Twitter wrapper\n",
    "import twitter\n",
    "\n",
    "# Twitter API keys go here\n",
    "#CONSUMER_KEY = ''\n",
    "#CONSUMER_SECRET = ''\n",
    "\n",
    "#OAUTH_TOKEN = ''\n",
    "#OAUTH_TOKEN_SECRET = ''\n",
    "\n",
    "\n",
    "CONSUMER_KEY = 'z3XcRz4Q29Tf0euTQAc8L3vbf'\n",
    "CONSUMER_SECRET = 'cgnX70ALspaaMtLmjgXGbevcpDUgnmphyOPMEjJXPf9EyfziOm'\n",
    "\n",
    "OAUTH_TOKEN = '3183721-djVqbJPwaQik8v1TnvO7v7ZreiBwuwj2T2aXUmAiFf'\n",
    "OAUTH_TOKEN_SECRET = 'cbKHKtpSOoLGWVZydzS4lxB8OT8wyZ02Q5lP0TRJfcWBb'\n",
    "\n",
    "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "twitter_api = twitter.Twitter(auth=auth)\n",
    "\n",
    "# Nothing to see by displaying twitter_api except that it's now a\n",
    "# defined variable\n",
    "\n",
    "print twitter_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wo0t! we've successfully used OAuth credentials to gain authorization to query Twitter's API!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take one of the common hashtags across trends and use it as the basis of a search query to fetch some tweets for further analysis. Here's a link to the <a class=\"ulink\" href=\"http://bit.ly/1a1l398\" target=\"\\_top\"><code class=\"literal\">GET search/tweets</code> resource</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "q = '#PopeinNYC' \n",
    "count = 100\n",
    "\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
    "\n",
    "search_results = twitter_api.search.tweets(q=q, count=count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# here's how a single tweet object looks like\n",
    "\n",
    "print json.dumps(search_results['statuses'][0], indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all statuses\n",
    "statuses = search_results['statuses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all users\n",
    "tweet_users = [x['user']['screen_name'] for x in statuses]\n",
    "tweet_users[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is metadata returned along with our search results -> it includes the parameters for continuing to query for \n",
    "# additional results (just like we did with IG)\n",
    "\n",
    "search_results['search_metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if we provide max_id -> we'll get tweets older than the current ones \n",
    "\n",
    "params = {a:b for a,b in [x.split('=') for x in search_results['search_metadata']['next_results'][1:].split('&')]}\n",
    "max_id = int(params['max_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# given the 'max_id' parameter now we iterate through the results\n",
    "\n",
    "search_results = twitter_api.search.tweets(q=q, count=count, max_id=max_id)\n",
    "statuses += search_results['statuses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(statuses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use a loop -> iterate multiple times to get many more tweets\n",
    "\n",
    "num_iterations = 30\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    params = {a:b for a,b in [x.split('=') for x in search_results['search_metadata']['next_results'][1:].split('&')]}\n",
    "    max_id = int(params['max_id'])    \n",
    "    search_results = twitter_api.search.tweets(q=q, count=count, max_id=max_id)\n",
    "    statuses += search_results['statuses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(statuses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save our data in pickled format - so that we don't ahve to grab it again if our machine crashes\n",
    "\n",
    "import pickle\n",
    "path = '/class/itpmssd/datasets/'\n",
    "\n",
    "pickle.dump(statuses, open(path+'%s_tw.p' % q,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a simple hashtag search. It is worth noting that Twitter's search API enables some more advanced queries - https://dev.twitter.com/docs/using-search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "status_texts = [ status['text'] \n",
    "                 for status in statuses ]\n",
    "\n",
    "print json.dumps(status_texts[0:5], indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "screen_names = [ user_mention['screen_name'] \n",
    "                 for status in statuses\n",
    "                     for user_mention in status['entities']['user_mentions'] ]\n",
    "\n",
    "print json.dumps(screen_names[0:5], indent=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtags = [ hashtag['text'] \n",
    "             for status in statuses\n",
    "                 for hashtag in status['entities']['hashtags'] ]\n",
    "\n",
    "print json.dumps(hashtags[0:15], indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute a collection of all words from all tweets\n",
    "words = [ w \n",
    "          for t in status_texts \n",
    "              for w in t.split() ]\n",
    "\n",
    "print json.dumps(words[0:5], indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "status_texts[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Tweets and Tweet Entities with Frequency Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From an empirical standpoint, counting observable things is the starting point for just about everything, and thus the starting point for any kind of statistical filtering or manipulation that strives to find what may be a faint signal in noisy data. Whereas we just extracted the first 5 items of each unranked list to get a feel for the data, let's now take a closer look at what's in the data by computing a frequency distribution and looking at the top 10 items in each list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the frequency distribution is a map of key/value\n",
    "      pairs corresponding to terms and their frequencies, so let's make\n",
    "      reviewing the results a little easier on the eyes by emitting a tabular\n",
    "      format. You can install a package called <code class=\"literal\">prettytable</code> by typing <strong class=\"userinput\"><code>pip install prettytable</code></strong> in a terminal; this\n",
    "      package provides a convenient way to emit a fixed-width tabular format\n",
    "      that can be easily copied-and-pasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for item in [words, screen_names, hashtags]:\n",
    "    c = Counter(item)\n",
    "    print c.most_common()[:10] # top 10\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "for label, data in (('Word', words), \n",
    "                    ('Screen Name', screen_names), \n",
    "                    ('Hashtag', hashtags)):\n",
    "    pt = PrettyTable(field_names=[label, 'Count']) \n",
    "    c = Counter(data)\n",
    "    [ pt.add_row(kv) for kv in c.most_common()[:10] ]\n",
    "    pt.align[label], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
    "    print pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used code and examples from Mining the Social Web, 2nd Edition - https://rawgit.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/master/ipynb/html/Chapter%201%20-%20Mining%20Twitter.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neat Link - https://github.com/lennerd/TwitterGraph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
