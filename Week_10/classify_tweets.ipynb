{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier - twitter data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- binary classifier: decides between two labels: positive, negative\n",
    "- multi-label classifier: can assign one or more labels to pieces of text\n",
    "\n",
    "The classifier learns from labeled feature sets (training data), and then classifies an unlabeled feature set. \n",
    "The labels can be either predefined or automatically extracted.\n",
    "A feature set is basically a key-value mapping of feature names to feature values. When classifying text, the feature names are usually words, and the values are all True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words Approach"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- constructs a word presence feature set\n",
    "- feature extraction is the process of transforming a list of words into a feature set\n",
    "- when using NLTK classifier, it expects dict style feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "import json\n",
    "\n",
    "#CONSUMER_KEY = ''\n",
    "#CONSUMER_SECRET = ''\n",
    "\n",
    "#OAUTH_TOKEN = ''\n",
    "#OAUTH_TOKEN_SECRET = ''\n",
    "\n",
    "\n",
    "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "twitter_api = twitter.Twitter(auth=auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q1 = 'donald trump' \n",
    "count = 100\n",
    "\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
    "search_results = twitter_api.search.tweets(q=q1, count=count)\n",
    "q1_texts = search_results['statuses']\n",
    "\n",
    "# use a loop\n",
    "num_iterations = 10\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    params = {a:b for a,b in [x.split('=') for x in search_results['search_metadata']['next_results'][1:].split('&')]}\n",
    "    max_id = int(params['max_id'])    \n",
    "    search_results = twitter_api.search.tweets(q=q1, count=count, max_id=max_id)\n",
    "    q1_texts += search_results['statuses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q1_texts = [status['text'] for status in q1_texts]\n",
    "words_trump = [w.lower() for t in q1_texts for w in t.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q1_texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q2 = 'kardashian' \n",
    "count = 100\n",
    "\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
    "search_results = twitter_api.search.tweets(q=q2, count=count)\n",
    "q2_tweets = search_results['statuses']\n",
    "\n",
    "# use a loop\n",
    "num_iterations = 10\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    params = {a:b for a,b in [x.split('=') for x in search_results['search_metadata']['next_results'][1:].split('&')]}\n",
    "    max_id = int(params['max_id'])    \n",
    "    search_results = twitter_api.search.tweets(q=q2, count=count, max_id=max_id)\n",
    "    q2_tweets += search_results['statuses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q2_texts = [status['text'] for status in q2_tweets]\n",
    "words_kardashian = [w.lower() for t in q2_texts for w in t.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q2_texts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare our featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "stub = re.compile('[^A-Za-z]')\n",
    "common_words = ['rt']\n",
    "\n",
    "def bag_of_non_stopwords(text):\n",
    "    # create array of words\n",
    "    words = [stub.sub('', w).lower() for w in text.split()]\n",
    "\n",
    "    # remove English stop words and common words\n",
    "    finalwords = set(words) - set(stopwords.words('english')) - set(common_words)\n",
    "    \n",
    "    # format feature set data object\n",
    "    featureset = dict([(word, True) for word in finalwords if not word.startswith('http') and len(word)>2])\n",
    "    \n",
    "    return featureset\n",
    "\n",
    "bag_of_non_stopwords(q1_texts[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def extract_features(text):\n",
    "    return bag_of_non_stopwords(text)\n",
    "\n",
    "label_features = defaultdict(list)\n",
    "\n",
    "for tweet_text in q2_texts:\n",
    "    features = extract_features(tweet_text)\n",
    "    label_features['kardashian'].append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_features['kardashian'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tweet_text in q1_texts:\n",
    "    features = extract_features(tweet_text)\n",
    "    label_features['trump'].append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_features['trump'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split the data into training / test sets -> 75/25% split\n",
    "def split_label_feats(lfeats, split=0.75):\n",
    "    train_feats = []\n",
    "    test_feats = []\n",
    "\n",
    "    for label, feats in lfeats.iteritems():\n",
    "        cutoff = int(len(feats) * split)\n",
    "        train_feats.extend([(feat, label) for feat in feats[:cutoff]])\n",
    "        test_feats.extend([(feat, label) for feat in feats[cutoff:]])\n",
    "\n",
    "    return train_feats, test_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split data into training/testing - (split = 0.75) by default\n",
    "train_feats, test_feats = split_label_feats(label_features)\n",
    "\n",
    "print len(train_feats)\n",
    "print len(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "nb = NaiveBayesClassifier.train(train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ex1_features = extract_features(\"protect us from terrorists\")\n",
    "nb.classify(ex1_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ex2_features = extract_features(\"pregnant with another baby !@#!@\")\n",
    "nb.classify(ex2_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "from nltk.classify.util import accuracy\n",
    "\n",
    "accuracy(nb, test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# getting classification probability of each label\n",
    "probs = nb.prob_classify(test_feats[6][0])\n",
    "\n",
    "print probs.samples()\n",
    "print 'chosen class:',probs.max()\n",
    "print 'P(trump)=',probs.prob('trump')\n",
    "print 'P(kardashian)=',probs.prob('kardashian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_feats[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# most informative feature - feature value will always be True\n",
    "\n",
    "nb.most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# more information on the chosen label\n",
    "\n",
    "nb.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
