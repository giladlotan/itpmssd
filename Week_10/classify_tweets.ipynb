{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier - twitter data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- binary classifier: decides between two labels: positive, negative\n",
    "- multi-label classifier: can assign one or more labels to pieces of text\n",
    "\n",
    "The classifier learns from labeled feature sets (training data), and then classifies an unlabeled feature set. \n",
    "The labels can be either predefined or automatically extracted.\n",
    "A feature set is basically a key-value mapping of feature names to feature values. When classifying text, the feature names are usually words, and the values are all True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words Approach"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- constructs a word presence feature set\n",
    "- feature extraction is the process of transforming a list of words into a feature set\n",
    "- when using NLTK classifier, it expects dict style feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "import json\n",
    "\n",
    "#CONSUMER_KEY = ''\n",
    "#CONSUMER_SECRET = ''\n",
    "\n",
    "#OAUTH_TOKEN = ''\n",
    "#OAUTH_TOKEN_SECRET = ''\n",
    "\n",
    "CONSUMER_KEY = 'KzLNf2VNYhdmbEeCl0E5lGAnh'\n",
    "CONSUMER_SECRET = 'PRRteY7pNeAdfC73MR469IH10JkgMwIRkelvvR4eVpiYfAo3Bh'\n",
    "\n",
    "OAUTH_TOKEN = '3183721-F6qIQaeelhdfW2ZTFRwXwJDmvSHWgvQcatqMK3DXee'\n",
    "OAUTH_TOKEN_SECRET = 'Itwk1uGJM1hWQGpWSAGCchIZ5hwOZ3UsX4iGsFvTUhOcQ'\n",
    "\n",
    "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "twitter_api = twitter.Twitter(auth=auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q1 = 'donald trump' \n",
    "count = 100\n",
    "\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
    "search_results = twitter_api.search.tweets(q=q1, count=count)\n",
    "q1_texts = search_results['statuses']\n",
    "\n",
    "# use a loop\n",
    "num_iterations = 10\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    params = {a:b for a,b in [x.split('=') for x in search_results['search_metadata']['next_results'][1:].split('&')]}\n",
    "    max_id = int(params['max_id'])    \n",
    "    search_results = twitter_api.search.tweets(q=q1, count=count, max_id=max_id)\n",
    "    q1_texts += search_results['statuses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q1_texts = [status['text'] for status in q1_texts]\n",
    "words_trump = [w.lower() for t in q1_texts for w in t.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'RT @billybragg: Time to stop taking the candidacy of Donald Trump as a joke https://t.co/0B4SD0hn3o',\n",
       " u\"I'm voting for Donald Trump because I never seen a president get assassinated before\",\n",
       " u'RT @iLikeSexDaily: a mosaic of donald trump created from over 5,000 dick pics https://t.co/o28oQ7DnOC',\n",
       " u'RT @CraigRozniecki: \"Donald Trump\\'s Plan for a Muslim Database Draws Comparisons to Nazi Germany\" by Vaughn Hillyard - https://t.co/c5ljVfY\\u2026',\n",
       " u'RT @iLikeSexDaily: a mosaic of donald trump created from over 5,000 dick pics https://t.co/o28oQ7DnOC',\n",
       " u'RT @merimartusa: adolf trump / donald hitler https://t.co/22cnnQ4yJO',\n",
       " u\"RT @TODAYshow: Donald Trump's plan for a Muslim database draws comparison to Nazi Germany: https://t.co/MzgLov1sgV https://t.co/NR3YSeuYcG\",\n",
       " u\"RT @counternotions: Donald Trump may or may not be a fascist, but he isn't quite the problem. \\n\\nTens of millions of Americans who may vote \\u2026\",\n",
       " u'RT @HasnaatMahmood: Donald Trump is literally hitler reincarnated expect for the fact that Hitler had a mustache and real hair https://t.co\\u2026',\n",
       " u'Trump launches Twitter tirade against Kasich after large super PAC ad buy https://t.co/3V24KGqbs3 via https://t.co/xoce9JQJjt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q2 = 'kardashian' \n",
    "count = 100\n",
    "\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
    "search_results = twitter_api.search.tweets(q=q2, count=count)\n",
    "q2_tweets = search_results['statuses']\n",
    "\n",
    "# use a loop\n",
    "num_iterations = 10\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    params = {a:b for a,b in [x.split('=') for x in search_results['search_metadata']['next_results'][1:].split('&')]}\n",
    "    max_id = int(params['max_id'])    \n",
    "    search_results = twitter_api.search.tweets(q=q2, count=count, max_id=max_id)\n",
    "    q2_tweets += search_results['statuses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q2_texts = [status['text'] for status in q2_tweets]\n",
    "words_kardashian = [w.lower() for t in q2_texts for w in t.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Photos of Kim Kardashian Before Was Famous\\U0001f602\\U0001f633 #FridayFeeling https://t.co/1yuTpH4pzK',\n",
       " u\"I'm now a D-List++ celebrity in Kim Kardashian: Hollywood. You can be famous too by playing on Android! https://t.co/eFJyyj7Eii\",\n",
       " u'Kerry Washington, Katie Holmes, Kourtney Kardashian Party at the Stylemakers Awards https://t.co/fCRhZk68ir',\n",
       " u'Forget Kim Kardashian! Meet Anastasia Kvitko',\n",
       " u'@asherahresearch If this were true, Justin Bieber or - God beware - Kim Kardashian would be omniscient. Yuk!',\n",
       " u\"I'm now an A-List celebrity in Kim Kardashian: Hollywood. You can be famous too by playing on Android! https://t.co/brZsqXJqcX\",\n",
       " u\"I'm now a B-List celebrity in Kim Kardashian: Hollywood. You can be famous too by playing on iPhone!  https://t.co/Mud5zO2cKZ\",\n",
       " u'Moniek 3 Erwin. @erwin_moniek Appealing Kim Kardashian West Images. Get started now: https://t.co/oOWGXIChEj',\n",
       " u'RT @shainamnbg_: dude, ur a desperate piece of shit',\n",
       " u'RT @brttmrtn: #NoteToSelf ; wag ipagpilitan ang sarili sa taong hindi ka gusto']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_texts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare our featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'donald': True,\n",
       " u'favor': True,\n",
       " u'hes': True,\n",
       " u'jpm': True,\n",
       " u'muslims': True,\n",
       " u'registrationdatabase': True,\n",
       " u'say': True,\n",
       " u'trump': True,\n",
       " u'via': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "stub = re.compile('[^A-Za-z]')\n",
    "common_words = ['rt']\n",
    "\n",
    "def bag_of_non_stopwords(text):\n",
    "    # create array of words\n",
    "    words = [stub.sub('', w).lower() for w in text.split()]\n",
    "\n",
    "    # remove English stop words and common words\n",
    "    finalwords = set(words) - set(stopwords.words('english')) - set(common_words)\n",
    "    \n",
    "    # format feature set data object\n",
    "    featureset = dict([(word, True) for word in finalwords if not word.startswith('http') and len(word)>2])\n",
    "    \n",
    "    return featureset\n",
    "\n",
    "bag_of_non_stopwords(q1_texts[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def extract_features(text):\n",
    "    return bag_of_non_stopwords(text)\n",
    "\n",
    "label_features = defaultdict(list)\n",
    "\n",
    "for tweet_text in q2_texts:\n",
    "    features = extract_features(tweet_text)\n",
    "    label_features['kardashian'].append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'android': True,\n",
       " u'celebrity': True,\n",
       " u'dlist': True,\n",
       " u'famous': True,\n",
       " u'hollywood': True,\n",
       " u'kardashian': True,\n",
       " u'kim': True,\n",
       " u'playing': True}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_features['kardashian'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tweet_text in q1_texts:\n",
    "    features = extract_features(tweet_text)\n",
    "    label_features['trump'].append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'comparisons': True,\n",
       " u'craigrozniecki': True,\n",
       " u'database': True,\n",
       " u'donald': True,\n",
       " u'draws': True,\n",
       " u'germany': True,\n",
       " u'hillyard': True,\n",
       " u'muslim': True,\n",
       " u'nazi': True,\n",
       " u'plan': True,\n",
       " u'trumps': True,\n",
       " u'vaughn': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_features['trump'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kardashian', 'trump']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split the data into training / test sets -> 75/25% split\n",
    "def split_label_feats(lfeats, split=0.75):\n",
    "    train_feats = []\n",
    "    test_feats = []\n",
    "\n",
    "    for label, feats in lfeats.iteritems():\n",
    "        cutoff = int(len(feats) * split)\n",
    "        train_feats.extend([(feat, label) for feat in feats[:cutoff]])\n",
    "        test_feats.extend([(feat, label) for feat in feats[cutoff:]])\n",
    "\n",
    "    return train_feats, test_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1650\n",
      "550\n"
     ]
    }
   ],
   "source": [
    "# Split data into training/testing - (split = 0.75) by default\n",
    "train_feats, test_feats = split_label_feats(label_features)\n",
    "\n",
    "print len(train_feats)\n",
    "print len(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "nb = NaiveBayesClassifier.train(train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trump'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1_features = extract_features(\"protect us from terrorists\")\n",
    "nb.classify(ex1_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kardashian'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex2_features = extract_features(\"pregnant with another baby !@#!@\")\n",
    "nb.classify(ex2_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9945454545454545"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "from nltk.classify.util import accuracy\n",
    "\n",
    "accuracy(nb, test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kardashian', 'trump']\n",
      "chosen class: kardashian\n",
      "P(trump)= 2.24713921377e-11\n",
      "P(kardashian)= 0.999999999978\n"
     ]
    }
   ],
   "source": [
    "# getting classification probability of each label\n",
    "probs = nb.prob_classify(test_feats[6][0])\n",
    "\n",
    "print probs.samples()\n",
    "print 'chosen class:',probs.max()\n",
    "print 'P(trump)=',probs.prob('trump')\n",
    "print 'P(kardashian)=',probs.prob('kardashian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({u'goes': True,\n",
       "  u'kardashian': True,\n",
       "  u'khloe': True,\n",
       "  u'lamar': True,\n",
       "  u'man': True,\n",
       "  u'odom': True,\n",
       "  u'rant': True,\n",
       "  u'twitter': True,\n",
       "  u'vows': True,\n",
       "  u'went': True},\n",
       " 'kardashian')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feats[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'kardashian', True),\n",
       " (u'donald', True),\n",
       " (u'kim', True),\n",
       " (u'trump', True),\n",
       " (u'asshole', True),\n",
       " (u'president', True),\n",
       " (u'kids', True),\n",
       " (u'would', True),\n",
       " (u'latest', True),\n",
       " (u'away', True)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most informative feature - feature value will always be True\n",
    "\n",
    "nb.most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "              kardashian = True           kardas : trump  =    453.7 : 1.0\n",
      "                  donald = True            trump : kardas =    188.1 : 1.0\n",
      "                     kim = True           kardas : trump  =    183.0 : 1.0\n",
      "                   trump = True            trump : kardas =    175.3 : 1.0\n",
      "                 asshole = True           kardas : trump  =     48.3 : 1.0\n",
      "               president = True            trump : kardas =     32.3 : 1.0\n",
      "                    kids = True           kardas : trump  =     23.7 : 1.0\n",
      "                   would = True            trump : kardas =     20.6 : 1.0\n",
      "                  latest = True           kardas : trump  =     19.8 : 1.0\n",
      "                    away = True           kardas : trump  =     19.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# more information on the chosen label\n",
    "\n",
    "nb.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
