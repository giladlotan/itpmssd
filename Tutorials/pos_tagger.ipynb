{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource u'tokenizers/punkt/english.pickle' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - u''\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4333fe17464f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mu\"Medical personnel returning to New York and New Jersey from the Ebola-riddled countries in West Africa will be automatically quarantined if they had direct contact with an infected person, officials announced Friday. New York Gov. Andrew Cuomo (D) and New Jersey Gov. Chris Christie (R) announced the decision at a joint news conference Friday at 7 World Trade Center. “We have to do more,” Cuomo said. “It’s too serious of a situation to leave it to the honor system of compliance.” They said that public-health officials at John F. Kennedy and Newark Liberty international airports, where enhanced screening for Ebola is taking place, would make the determination on who would be quarantined. Anyone who had direct contact with an Ebola patient in Liberia, Sierra Leone or Guinea will be quarantined. In addition, anyone who traveled there but had no such contact would be actively monitored and possibly quarantined, authorities said. This news came a day after a doctor who had treated Ebola patients in Guinea was diagnosed in Manhattan, becoming the fourth person diagnosed with the virus in the United States and the first outside of Dallas. And the decision came not long after a health-care worker who had treated Ebola patients arrived at Newark, one of five airports where people traveling from West Africa to the United States are encountering the stricter screening rules.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/nltk/tokenize/__init__.pyc\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \"\"\"\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/nltk/data.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raw'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/nltk/data.pyc\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nltk'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'file'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/nltk/data.pyc\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'*'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource u'tokenizers/punkt/english.pickle' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - u''\n**********************************************************************"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "text = u\"Medical personnel returning to New York and New Jersey from the Ebola-riddled countries in West Africa will be automatically quarantined if they had direct contact with an infected person, officials announced Friday. New York Gov. Andrew Cuomo (D) and New Jersey Gov. Chris Christie (R) announced the decision at a joint news conference Friday at 7 World Trade Center. “We have to do more,” Cuomo said. “It’s too serious of a situation to leave it to the honor system of compliance.” They said that public-health officials at John F. Kennedy and Newark Liberty international airports, where enhanced screening for Ebola is taking place, would make the determination on who would be quarantined. Anyone who had direct contact with an Ebola patient in Liberia, Sierra Leone or Guinea will be quarantined. In addition, anyone who traveled there but had no such contact would be actively monitored and possibly quarantined, authorities said. This news came a day after a doctor who had treated Ebola patients in Guinea was diagnosed in Manhattan, becoming the fourth person diagnosed with the virus in the United States and the first outside of Dallas. And the decision came not long after a health-care worker who had treated Ebola patients arrived at Newark, one of five airports where people traveling from West Africa to the United States are encountering the stricter screening rules.\"\n",
    "\n",
    "for sent in nltk.sent_tokenize(text): \n",
    "    print sent\n",
    "    print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> d\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> l\n",
      "Packages:\n",
      "  [ ] abc................. Australian Broadcasting Commission 2006\n",
      "  [ ] alpino.............. Alpino Dutch Treebank\n",
      "  [ ] basque_grammars..... Grammars for Basque\n",
      "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
      "                           Extraction Systems in Biology)\n",
      "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
      "  [ ] book_grammars....... Grammars from NLTK Book\n",
      "  [ ] brown............... Brown Corpus\n",
      "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
      "  [ ] cess_cat............ CESS-CAT Treebank\n",
      "  [ ] cess_esp............ CESS-ESP Treebank\n",
      "  [ ] chat80.............. Chat-80 Data Files\n",
      "  [ ] city_database....... City Database\n",
      "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
      "  [ ] comparative_sentences Comparative Sentence Dataset\n",
      "  [ ] comtrans............ ComTrans Corpus Sample\n",
      "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
      "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
      "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
      "                           and Basque Subset)\n",
      "Hit Enter to continue: \n",
      "  [ ] crubadan............ Crubadan Corpus\n",
      "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
      "  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
      "                           Corpus\n",
      "  [ ] floresta............ Portuguese Treebank\n",
      "  [ ] framenet_v15........ FrameNet 1.5\n",
      "  [ ] gazetteers.......... Gazeteer Lists\n",
      "  [ ] genesis............. Genesis Corpus\n",
      "  [ ] gutenberg........... Project Gutenberg Selections\n",
      "  [ ] hmm_treebank_pos_tagger Treebank Part of Speech Tagger (HMM)\n",
      "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
      "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
      "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
      "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
      "                           ChaSen format)\n",
      "  [ ] kimmo............... PC-KIMMO Data Files\n",
      "  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n",
      "  [ ] large_grammars...... Large context-free and feature-based grammars\n",
      "                           for parser comparison\n",
      "  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n",
      "  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n",
      "                           part-of-speech tags\n",
      "Hit Enter to continue: \n",
      "  [ ] machado............. Machado de Assis -- Obra Completa\n",
      "  [ ] masc_tagged......... MASC Tagged Corpus\n",
      "  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n",
      "  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n",
      "  [ ] moses_sample........ Moses Sample Models\n",
      "  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n",
      "  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n",
      "  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n",
      "  [ ] nombank.1.0......... NomBank Corpus 1.0\n",
      "  [ ] nps_chat............ NPS Chat\n",
      "  [ ] oanc_masc........... Open American National Corpus: Manually\n",
      "                           Annotated Sub-Corpus\n",
      "  [ ] omw................. Open Multilingual Wordnet\n",
      "  [ ] opinion_lexicon..... Opinion Lexicon\n",
      "  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n",
      "  [ ] paradigms........... Paradigm Corpus\n",
      "  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n",
      "                           Evaluation Shared Task\n",
      "  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n",
      "  [ ] pl196x.............. Polish language of the XX century sixties\n",
      "  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n",
      "Hit Enter to continue: \n",
      "  [ ] problem_reports..... Problem Report Corpus\n",
      "  [ ] product_reviews_1... Product Reviews (5 Products)\n",
      "  [ ] product_reviews_2... Product Reviews (9 Products)\n",
      "  [ ] propbank............ Proposition Bank Corpus 1.0\n",
      "  [ ] pros_cons........... Pros and Cons\n",
      "  [ ] ptb................. Penn Treebank\n",
      "  [ ] punkt............... Punkt Tokenizer Models\n",
      "  [ ] qc.................. Experimental Data for Question Classification\n",
      "  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n",
      "                           version\n",
      "  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n",
      "                           Portuguesa)\n",
      "  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n",
      "  [ ] sample_grammars..... Sample Grammars\n",
      "  [ ] semcor.............. SemCor 3.0\n",
      "  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n",
      "  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n",
      "  [ ] sentiwordnet........ SentiWordNet\n",
      "  [ ] shakespeare......... Shakespeare XML Corpus Sample\n",
      "  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n",
      "  [ ] smultron............ SMULTRON Corpus Sample\n",
      "Hit Enter to continue: \n",
      "  [ ] snowball_data....... Snowball Data\n",
      "  [ ] spanish_grammars.... Grammars for Spanish\n",
      "  [ ] state_union......... C-Span State of the Union Address Corpus\n",
      "  [ ] subjectivity........ Subjectivity Dataset v1.0\n",
      "  [ ] swadesh............. Swadesh Wordlists\n",
      "  [ ] switchboard......... Switchboard Corpus Sample\n",
      "  [ ] tagsets............. Help on Tagsets\n",
      "  [ ] timit............... TIMIT Corpus Sample\n",
      "  [ ] toolbox............. Toolbox Sample Files\n",
      "  [ ] treebank............ Penn Treebank Sample\n",
      "  [ ] twitter_samples..... Twitter Samples\n",
      "  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n",
      "                           (Unicode Version)\n",
      "  [ ] udhr................ Universal Declaration of Human Rights Corpus\n",
      "  [ ] unicode_samples..... Unicode Samples\n",
      "  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n",
      "  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n",
      "  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n",
      "  [ ] webtext............. Web Text Corpus\n",
      "  [ ] word2vec_sample..... Word2Vec Sample\n",
      "  [ ] wordnet............. WordNet\n",
      "Hit Enter to continue: \n",
      "  [ ] wordnet_ic.......... WordNet-InfoContent\n",
      "  [ ] words............... Word Lists\n",
      "  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n",
      "                           English Prose\n",
      "\n",
      "Collections:\n",
      "  [P] all-corpora......... All the corpora\n",
      "  [P] all................. All packages\n",
      "  [P] book................ Everything used in the NLTK Book\n",
      "\n",
      "([*] marks installed packages; [P] marks partially installed collections)\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> punkt\n",
      "    Downloading package punkt to /root/nltk_data...\n",
      "      Unzipping tokenizers/punkt.zip.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to download: \n",
    "#      - averaged_perceptron_tagger\n",
    "#      - punkt\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical personnel returning to New York and New Jersey from the Ebola-riddled countries in West Africa will be automatically quarantined if they had direct contact with an infected person, officials announced Friday.\n",
      "\n",
      "New York Gov.\n",
      "\n",
      "Andrew Cuomo (D) and New Jersey Gov.\n",
      "\n",
      "Chris Christie (R) announced the decision at a joint news conference Friday at 7 World Trade Center.\n",
      "\n",
      "“We have to do more,” Cuomo said.\n",
      "\n",
      "“It’s too serious of a situation to leave it to the honor system of compliance.” They said that public-health officials at John F. Kennedy and Newark Liberty international airports, where enhanced screening for Ebola is taking place, would make the determination on who would be quarantined.\n",
      "\n",
      "Anyone who had direct contact with an Ebola patient in Liberia, Sierra Leone or Guinea will be quarantined.\n",
      "\n",
      "In addition, anyone who traveled there but had no such contact would be actively monitored and possibly quarantined, authorities said.\n",
      "\n",
      "This news came a day after a doctor who had treated Ebola patients in Guinea was diagnosed in Manhattan, becoming the fourth person diagnosed with the virus in the United States and the first outside of Dallas.\n",
      "\n",
      "And the decision came not long after a health-care worker who had treated Ebola patients arrived at Newark, one of five airports where people traveling from West Africa to the United States are encountering the stricter screening rules.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = u\"Medical personnel returning to New York and New Jersey from the Ebola-riddled countries in West Africa will be automatically quarantined if they had direct contact with an infected person, officials announced Friday. New York Gov. Andrew Cuomo (D) and New Jersey Gov. Chris Christie (R) announced the decision at a joint news conference Friday at 7 World Trade Center. “We have to do more,” Cuomo said. “It’s too serious of a situation to leave it to the honor system of compliance.” They said that public-health officials at John F. Kennedy and Newark Liberty international airports, where enhanced screening for Ebola is taking place, would make the determination on who would be quarantined. Anyone who had direct contact with an Ebola patient in Liberia, Sierra Leone or Guinea will be quarantined. In addition, anyone who traveled there but had no such contact would be actively monitored and possibly quarantined, authorities said. This news came a day after a doctor who had treated Ebola patients in Guinea was diagnosed in Manhattan, becoming the fourth person diagnosed with the virus in the United States and the first outside of Dallas. And the decision came not long after a health-care worker who had treated Ebola patients arrived at Newark, one of five airports where people traveling from West Africa to the United States are encountering the stricter screening rules.\"\n",
    "\n",
    "for sentence in nltk.sent_tokenize(text): \n",
    "    print sentence\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Medical', u'personnel', u'returning', u'to', u'New', u'York', u'and', u'New', u'Jersey', u'from', u'the', u'Ebola-riddled', u'countries', u'in', u'West', u'Africa', u'will', u'be', u'automatically', u'quarantined', u'if', u'they', u'had', u'direct', u'contact', u'with', u'an', u'infected', u'person', u',', u'officials', u'announced', u'Friday', u'.']\n",
      "\n",
      "[u'New', u'York', u'Gov', u'.']\n",
      "\n",
      "[u'Andrew', u'Cuomo', u'(', u'D', u')', u'and', u'New', u'Jersey', u'Gov', u'.']\n",
      "\n",
      "[u'Chris', u'Christie', u'(', u'R', u')', u'announced', u'the', u'decision', u'at', u'a', u'joint', u'news', u'conference', u'Friday', u'at', u'7', u'World', u'Trade', u'Center', u'.']\n",
      "\n",
      "[u'\\u201cWe', u'have', u'to', u'do', u'more', u',', u'\\u201d', u'Cuomo', u'said', u'.']\n",
      "\n",
      "[u'\\u201cIt\\u2019s', u'too', u'serious', u'of', u'a', u'situation', u'to', u'leave', u'it', u'to', u'the', u'honor', u'system', u'of', u'compliance.\\u201d', u'They', u'said', u'that', u'public-health', u'officials', u'at', u'John', u'F.', u'Kennedy', u'and', u'Newark', u'Liberty', u'international', u'airports', u',', u'where', u'enhanced', u'screening', u'for', u'Ebola', u'is', u'taking', u'place', u',', u'would', u'make', u'the', u'determination', u'on', u'who', u'would', u'be', u'quarantined', u'.']\n",
      "\n",
      "[u'Anyone', u'who', u'had', u'direct', u'contact', u'with', u'an', u'Ebola', u'patient', u'in', u'Liberia', u',', u'Sierra', u'Leone', u'or', u'Guinea', u'will', u'be', u'quarantined', u'.']\n",
      "\n",
      "[u'In', u'addition', u',', u'anyone', u'who', u'traveled', u'there', u'but', u'had', u'no', u'such', u'contact', u'would', u'be', u'actively', u'monitored', u'and', u'possibly', u'quarantined', u',', u'authorities', u'said', u'.']\n",
      "\n",
      "[u'This', u'news', u'came', u'a', u'day', u'after', u'a', u'doctor', u'who', u'had', u'treated', u'Ebola', u'patients', u'in', u'Guinea', u'was', u'diagnosed', u'in', u'Manhattan', u',', u'becoming', u'the', u'fourth', u'person', u'diagnosed', u'with', u'the', u'virus', u'in', u'the', u'United', u'States', u'and', u'the', u'first', u'outside', u'of', u'Dallas', u'.']\n",
      "\n",
      "[u'And', u'the', u'decision', u'came', u'not', u'long', u'after', u'a', u'health-care', u'worker', u'who', u'had', u'treated', u'Ebola', u'patients', u'arrived', u'at', u'Newark', u',', u'one', u'of', u'five', u'airports', u'where', u'people', u'traveling', u'from', u'West', u'Africa', u'to', u'the', u'United', u'States', u'are', u'encountering', u'the', u'stricter', u'screening', u'rules', u'.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in nltk.sent_tokenize(text):\n",
    "    print list(nltk.word_tokenize(sentence))\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Medical', 'JJ'), (u'personnel', 'NNS'), (u'returning', 'VBG'), (u'to', 'TO'), (u'New', 'NNP'), (u'York', 'NNP'), (u'and', 'CC'), (u'New', 'NNP'), (u'Jersey', 'NNP'), (u'from', 'IN'), (u'the', 'DT'), (u'Ebola-riddled', 'JJ'), (u'countries', 'NNS'), (u'in', 'IN'), (u'West', 'NNP'), (u'Africa', 'NNP'), (u'will', 'MD'), (u'be', 'VB'), (u'automatically', 'RB'), (u'quarantined', 'VBN'), (u'if', 'IN'), (u'they', 'PRP'), (u'had', 'VBD'), (u'direct', 'JJ'), (u'contact', 'NN'), (u'with', 'IN'), (u'an', 'DT'), (u'infected', 'JJ'), (u'person', 'NN'), (u',', ','), (u'officials', 'NNS'), (u'announced', 'VBD'), (u'Friday', 'NNP'), (u'.', '.')]\n",
      "\n",
      "[(u'New', 'NNP'), (u'York', 'NNP'), (u'Gov', 'NNP'), (u'.', '.')]\n",
      "\n",
      "[(u'Andrew', 'NNP'), (u'Cuomo', 'NNP'), (u'(', '('), (u'D', 'NNP'), (u')', ')'), (u'and', 'CC'), (u'New', 'NNP'), (u'Jersey', 'NNP'), (u'Gov', 'NNP'), (u'.', '.')]\n",
      "\n",
      "[(u'Chris', 'NNP'), (u'Christie', 'NNP'), (u'(', '('), (u'R', 'NNP'), (u')', ')'), (u'announced', 'VBD'), (u'the', 'DT'), (u'decision', 'NN'), (u'at', 'IN'), (u'a', 'DT'), (u'joint', 'JJ'), (u'news', 'NN'), (u'conference', 'NN'), (u'Friday', 'NNP'), (u'at', 'IN'), (u'7', 'CD'), (u'World', 'NNP'), (u'Trade', 'NNP'), (u'Center', 'NNP'), (u'.', '.')]\n",
      "\n",
      "[(u'\\u201cWe', 'NNS'), (u'have', 'VBP'), (u'to', 'TO'), (u'do', 'VB'), (u'more', 'JJR'), (u',', ','), (u'\\u201d', 'NNP'), (u'Cuomo', 'NNP'), (u'said', 'VBD'), (u'.', '.')]\n",
      "\n",
      "[(u'\\u201cIt\\u2019s', 'VB'), (u'too', 'RB'), (u'serious', 'JJ'), (u'of', 'IN'), (u'a', 'DT'), (u'situation', 'NN'), (u'to', 'TO'), (u'leave', 'VB'), (u'it', 'PRP'), (u'to', 'TO'), (u'the', 'DT'), (u'honor', 'NN'), (u'system', 'NN'), (u'of', 'IN'), (u'compliance.\\u201d', 'NN'), (u'They', 'PRP'), (u'said', 'VBD'), (u'that', 'IN'), (u'public-health', 'NN'), (u'officials', 'NNS'), (u'at', 'IN'), (u'John', 'NNP'), (u'F.', 'NNP'), (u'Kennedy', 'NNP'), (u'and', 'CC'), (u'Newark', 'NNP'), (u'Liberty', 'NNP'), (u'international', 'JJ'), (u'airports', 'NNS'), (u',', ','), (u'where', 'WRB'), (u'enhanced', 'VBN'), (u'screening', 'NN'), (u'for', 'IN'), (u'Ebola', 'NNP'), (u'is', 'VBZ'), (u'taking', 'VBG'), (u'place', 'NN'), (u',', ','), (u'would', 'MD'), (u'make', 'VB'), (u'the', 'DT'), (u'determination', 'NN'), (u'on', 'IN'), (u'who', 'WP'), (u'would', 'MD'), (u'be', 'VB'), (u'quarantined', 'VBN'), (u'.', '.')]\n",
      "\n",
      "[(u'Anyone', 'NN'), (u'who', 'WP'), (u'had', 'VBD'), (u'direct', 'JJ'), (u'contact', 'NN'), (u'with', 'IN'), (u'an', 'DT'), (u'Ebola', 'NNP'), (u'patient', 'NN'), (u'in', 'IN'), (u'Liberia', 'NNP'), (u',', ','), (u'Sierra', 'NNP'), (u'Leone', 'NNP'), (u'or', 'CC'), (u'Guinea', 'NNP'), (u'will', 'MD'), (u'be', 'VB'), (u'quarantined', 'VBN'), (u'.', '.')]\n",
      "\n",
      "[(u'In', 'IN'), (u'addition', 'NN'), (u',', ','), (u'anyone', 'NN'), (u'who', 'WP'), (u'traveled', 'VBD'), (u'there', 'RB'), (u'but', 'CC'), (u'had', 'VBD'), (u'no', 'DT'), (u'such', 'JJ'), (u'contact', 'NN'), (u'would', 'MD'), (u'be', 'VB'), (u'actively', 'RB'), (u'monitored', 'VBN'), (u'and', 'CC'), (u'possibly', 'RB'), (u'quarantined', 'VBD'), (u',', ','), (u'authorities', 'NNS'), (u'said', 'VBD'), (u'.', '.')]\n",
      "\n",
      "[(u'This', 'DT'), (u'news', 'NN'), (u'came', 'VBD'), (u'a', 'DT'), (u'day', 'NN'), (u'after', 'IN'), (u'a', 'DT'), (u'doctor', 'NN'), (u'who', 'WP'), (u'had', 'VBD'), (u'treated', 'VBN'), (u'Ebola', 'NNP'), (u'patients', 'NNS'), (u'in', 'IN'), (u'Guinea', 'NNP'), (u'was', 'VBD'), (u'diagnosed', 'VBN'), (u'in', 'IN'), (u'Manhattan', 'NNP'), (u',', ','), (u'becoming', 'VBG'), (u'the', 'DT'), (u'fourth', 'JJ'), (u'person', 'NN'), (u'diagnosed', 'VBD'), (u'with', 'IN'), (u'the', 'DT'), (u'virus', 'NN'), (u'in', 'IN'), (u'the', 'DT'), (u'United', 'NNP'), (u'States', 'NNPS'), (u'and', 'CC'), (u'the', 'DT'), (u'first', 'JJ'), (u'outside', 'NN'), (u'of', 'IN'), (u'Dallas', 'NNP'), (u'.', '.')]\n",
      "\n",
      "[(u'And', 'CC'), (u'the', 'DT'), (u'decision', 'NN'), (u'came', 'VBD'), (u'not', 'RB'), (u'long', 'RB'), (u'after', 'IN'), (u'a', 'DT'), (u'health-care', 'JJ'), (u'worker', 'NN'), (u'who', 'WP'), (u'had', 'VBD'), (u'treated', 'VBN'), (u'Ebola', 'NNP'), (u'patients', 'NNS'), (u'arrived', 'VBD'), (u'at', 'IN'), (u'Newark', 'NNP'), (u',', ','), (u'one', 'CD'), (u'of', 'IN'), (u'five', 'CD'), (u'airports', 'NNS'), (u'where', 'WRB'), (u'people', 'NNS'), (u'traveling', 'VBG'), (u'from', 'IN'), (u'West', 'NNP'), (u'Africa', 'NNP'), (u'to', 'TO'), (u'the', 'DT'), (u'United', 'NNP'), (u'States', 'NNPS'), (u'are', 'VBP'), (u'encountering', 'VBG'), (u'the', 'DT'), (u'stricter', 'NN'), (u'screening', 'NN'), (u'rules', 'NNS'), (u'.', '.')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in nltk.sent_tokenize(text):\n",
    "    print list(nltk.pos_tag(nltk.word_tokenize(sentence)))\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
