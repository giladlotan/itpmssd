{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "\n",
    "# XXX: Go to http://dev.twitter.com/apps/new to create an app and get values\n",
    "# for these credentials, which you'll need to provide in place of these\n",
    "# empty string values that are defined as placeholders.\n",
    "# See https://dev.twitter.com/docs/auth/oauth for more information \n",
    "# on Twitter's OAuth implementation.\n",
    "\n",
    "# Twitter API keys go here\n",
    "#CONSUMER_KEY = ''\n",
    "#CONSUMER_SECRET = ''\n",
    "\n",
    "#OAUTH_TOKEN = ''\n",
    "#OAUTH_TOKEN_SECRET = ''\n",
    "\n",
    "\n",
    "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "twitter_api = twitter.Twitter(auth=auth)\n",
    "\n",
    "# Nothing to see by displaying twitter_api except that it's now a\n",
    "# defined variable\n",
    "\n",
    "print twitter_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wo0t! we've successfully used OAuth credentials to gain authorization to query Twitter's API!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter's Trending Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get list of available trends\n",
    "available_trends = twitter_api.trends.available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(available_trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "print json.dumps(available_trends, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The Yahoo! Where On Earth ID for the entire world is 1.\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/trends/place and\n",
    "# http://developer.yahoo.com/geo/geoplanet/\n",
    "# https://dev.twitter.com/rest/reference/get/trends/available\n",
    "\n",
    "WORLD_WOE_ID = 1\n",
    "US_WOE_ID = 23424977\n",
    "EDINBURGH_WOE_ID = 19344\n",
    "\n",
    "# Prefix ID with the underscore for query string parameterization.\n",
    "# Without the underscore, the twitter package appends the ID value\n",
    "# to the URL itself as a special case keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edinburgh_trends = twitter_api.trends.place(_id=EDINBURGH_WOE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print json.dumps(edinburgh_trends, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "world_trends = twitter_api.trends.place(_id=WORLD_WOE_ID)\n",
    "us_trends = twitter_api.trends.place(_id=US_WOE_ID)\n",
    "\n",
    "print json.dumps(world_trends, indent=1)\n",
    "print\n",
    "print json.dumps(us_trends, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# see available trend locations\n",
    "twitter_api.trends.available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pattern for using the twitter module is simple and predictable: instantiate the Twitter class with an object chain corresponding to a base URL and then invoke methods on the object that correspond to URL contexts. For example,  twitter_api._trends.place(WORLD_WOE_ID) initiates an HTTP call to GET https://api.twitter.com/1.1/trends/place.json?id=1. Note the URL mapping to the object chain that's constructed with the  twitter package to make the request and how query string parameters are passed in as keyword arguments. To use the twitter package for arbitrary API requests, you generally construct the request in that kind of straightforward manner, with just a couple of minor caveats that we'll encounter soon enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter imposes <span class=\"emphasis\"><em>rate limits</em></span> on how many requests an application can make to any given API\n",
    "      resource within a given time window. Twitter's <a class=\"ulink\" href=\"http://bit.ly/1a1l257\" target=\"\\_top\">rate limits</a> are well documented, and\n",
    "      each individual API resource also states its particular limits for your\n",
    "      convenience. For example, the API request that we just issued for trends\n",
    "      limits applications to 15 requests per 15-minute window. For more nuanced information on\n",
    "      how Twitter's rate limits work, see <a class=\"ulink\" href=\"http://bit.ly/1a1l2ly\" target=\"\\_top\">REST API Rate\n",
    "      Limiting in v1.1</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_rate_limit(t, call_type):\n",
    "    if call_type=='trends_place':\n",
    "        limit = t.application.rate_limit_status()\n",
    "        return limit['resources']['trends']['/trends/place']['remaining']\n",
    "    \n",
    "    elif call_type=='lists_memberships':\n",
    "        limit = t.application.rate_limit_status()\n",
    "        return limit['resources']['lists']['/lists/memberships']['remaining']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote><div><strong>Note:</strong></div><p><a class=\"ulink\" href=\"http://bit.ly/1a1l2lJ\" target=\"\\_top\">JSON</a> is a data\n",
    "        exchange format that you will encounter on a regular\n",
    "        basis. In a nutshell, JSON provides a way to arbitrarily store maps,\n",
    "        lists, primitives such as numbers and strings, and combinations\n",
    "        thereof. In other words, you can theoretically model just about\n",
    "        anything with JSON should you desire to do so.</p></blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print json.dumps(world_trends, indent=1)\n",
    "print\n",
    "print json.dumps(us_trends, indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's use Python Sets to compare Worldwide vs. US trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a set refers to the mathematical notion of a data structure that stores an unordered collection of unique items and can be computed upon with other sets of items and setwise operations. For example, a setwise intersection computes common items between sets, a setwise union combines all of the items from sets, and the setwise difference among sets acts sort of like a subtraction operation in which items from one set are removed from another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using <a href=\"https://docs.python.org/2/tutorial/datastructures.html#list-comprehensions\">list comprehensions</a>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "world_trends_list = []\n",
    "\n",
    "for t in world_trends[0]['trends']:\n",
    "    print t['name']\n",
    "    world_trends_list.append(t['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "world_trends_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "world_trends_old = [x['name'] for x in world_trends[0]['trends']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "world_trends_new = twitter_api.trends.place(_id=WORLD_WOE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "world_trends_new = [x['name'] for x in world_trends_new[0]['trends']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print world_trends_new\n",
    "print ''\n",
    "print world_trends_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "world_trends_old_set = set(world_trends_old)\n",
    "world_trends_new_set = set(world_trends_new)\n",
    "\n",
    "world_trends_new_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "common_trends = world_trends_old_set.intersection(world_trends_new_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "common_trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "world_trends_set = set([trend['name'] \n",
    "                        for trend in world_trends[0]['trends']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "us_trends_set = set([trend['name'] \n",
    "                     for trend in us_trends[0]['trends']]) \n",
    "\n",
    "common_trends = world_trends_set.intersection(us_trends_set)\n",
    "\n",
    "print common_trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take one of the common hashtags across trends and use it as the basis of a search query to fetch some tweets for further analysis. Here's a link to the <a class=\"ulink\" href=\"http://bit.ly/1a1l398\" target=\"\\_top\"><code class=\"literal\">GET search/tweets</code> resource</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = '#ebola' \n",
    "count = 100\n",
    "\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
    "\n",
    "search_results = twitter_api.search.tweets(q=q, count=count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print json.dumps(search_results, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statuses = search_results['statuses']\n",
    "tweet_users = [x['user']['screen_name'] for x in statuses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print json.dumps(search_results, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_results['search_metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if we provide max_id -> we'll get tweets older than the current ones \n",
    "params = {a:b for a,b in [x.split('=') for x in search_results['search_metadata']['next_results'][1:].split('&')]}\n",
    "max_id = int(params['max_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statuses = search_results['statuses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_results = twitter_api.search.tweets(q=q, count=count, max_id=max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statuses += search_results['statuses']\n",
    "\n",
    "print json.dumps(search_results['statuses'], indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(statuses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use a loop\n",
    "num_iterations = 150\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    params = {a:b for a,b in [x.split('=') for x in search_results['search_metadata']['next_results'][1:].split('&')]}\n",
    "    max_id = int(params['max_id'])    \n",
    "    search_results = twitter_api.search.tweets(q=q, count=count, max_id=max_id)\n",
    "    statuses += search_results['statuses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(statuses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Iterate through 5 more batches of results by following the cursor\n",
    "num_iterations = 5\n",
    "for _ in range(num_iterations):\n",
    "    print \"Length of statuses\", len(statuses)\n",
    "    try:\n",
    "        next_results = search_results['search_metadata']['next_results']\n",
    "        \n",
    "    # python raises a KeyError whenever a dict() object is requested and the key is not in the dictionary\n",
    "    except KeyError, e: # No more results when next_results doesn't exist\n",
    "        print json.dumps(search_results['search_metadata'], indent=1)\n",
    "        break\n",
    "        \n",
    "    # Create a dictionary from next_results, which has the following form:\n",
    "    # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
    "    print next_results[1:]\n",
    "    \n",
    "    kwargs = dict([ kv.split('=') for kv in next_results[1:].replace('%25','%').split(\"&\") ])\n",
    "    print kwargs\n",
    "    print ''\n",
    "    \n",
    "    search_results = twitter_api.search.tweets(**kwargs)\n",
    "    #search_results = twitter_api.search.tweets(q=kwargs['q'].replace('%25','%'), count=kwargs['count'], include_entities=1, max_id=kwargs['max_id'])\n",
    "    statuses += search_results['statuses']\n",
    "\n",
    "# Show one sample search result by slicing the list...\n",
    "#print json.dumps(statuses[0], indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a simple hashtag search. It is worth noting that Twitter's search API enables some more advanced queries - https://dev.twitter.com/docs/using-search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search results contain a special search_metadata node that embeds a next_results field with a query string that provides the basis of a subsequent query. If we weren't using a library like twitter to make the HTTP requests for us, this preconstructed query string would just be appended to the Search API URL, and we'd update it with additional parameters for handling OAuth. However, since we are not making our HTTP requests directly, we must parse the query string into its constituent key/value pairs and provide them as keyword arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "status_texts = [ status['text'] \n",
    "                 for status in statuses ]\n",
    "\n",
    "print json.dumps(status_texts[0:5], indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "screen_names = [ user_mention['screen_name'] \n",
    "                 for status in statuses\n",
    "                     for user_mention in status['entities']['user_mentions'] ]\n",
    "\n",
    "print json.dumps(screen_names[0:5], indent=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtags = [ hashtag['text'] \n",
    "             for status in statuses\n",
    "                 for hashtag in status['entities']['hashtags'] ]\n",
    "\n",
    "print json.dumps(hashtags[0:15], indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute a collection of all words from all tweets\n",
    "words = [ w \n",
    "          for t in status_texts \n",
    "              for w in t.split() ]\n",
    "\n",
    "print json.dumps(words[0:5], indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "status_texts[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Tweets and Tweet Entities with Frequency Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From an empirical standpoint, counting observable things is the starting point for just about everything, and thus the starting point for any kind of statistical filtering or manipulation that strives to find what may be a faint signal in noisy data. Whereas we just extracted the first 5 items of each unranked list to get a feel for the data, let's now take a closer look at what's in the data by computing a frequency distribution and looking at the top 10 items in each list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the frequency distribution is a map of key/value\n",
    "      pairs corresponding to terms and their frequencies, so let's make\n",
    "      reviewing the results a little easier on the eyes by emitting a tabular\n",
    "      format. You can install a package called <code class=\"literal\">prettytable</code> by typing <strong class=\"userinput\"><code>pip install prettytable</code></strong> in a terminal; this\n",
    "      package provides a convenient way to emit a fixed-width tabular format\n",
    "      that can be easily copied-and-pasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for item in [words, screen_names, hashtags]:\n",
    "    c = Counter(item)\n",
    "    print c.most_common()[:10] # top 10\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "for label, data in (('Word', words), \n",
    "                    ('Screen Name', screen_names), \n",
    "                    ('Hashtag', hashtags)):\n",
    "    pt = PrettyTable(field_names=[label, 'Count']) \n",
    "    c = Counter(data)\n",
    "    [ pt.add_row(kv) for kv in c.most_common()[:10] ]\n",
    "    pt.align[label], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
    "    print pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-occurence Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting question to ask is: which pairs of words co-occur in the same tweets? We can find these relations and use them to construct a graph using NetworkX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# functions that help us construct the graph\n",
    "\n",
    "def graph_add_node(n, g):\n",
    "    try:\n",
    "        if g.has_node(n):\n",
    "            g.node[n]['weight']+=1\n",
    "        else:\n",
    "            g.add_node(n)\n",
    "            g.node[n]['label'] = n\n",
    "            g.node[n]['weight'] = 1\n",
    "    except:\n",
    "        return\n",
    "            \n",
    "def graph_add_edge(n1, n2, g):\n",
    "    if g.has_edge(n1, n2):\n",
    "        g[n1][n2]['weight']+=1\n",
    "    else:\n",
    "        g.add_edge(n1,n2)\n",
    "        g[n1][n2]['weight']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(status_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get word co-occurence\n",
    "from itertools import combinations\n",
    "\n",
    "g = nx.Graph()\n",
    "\n",
    "for t in status_texts:\n",
    "    for w in t.split():\n",
    "        graph_add_node(w,g)\n",
    "        \n",
    "    for w1, w2 in combinations(t.split(),2):\n",
    "        graph_add_edge(w1, w2, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'nodes:', g.number_of_nodes()\n",
    "print 'edges:', g.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "for w1, w2 in combinations(status_texts[0].split(),2):\n",
    "    print w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output file\n",
    "nx.write_gexf(g, '%s_tweet_graph.gexf' % q)\n",
    "print '%s_tweet_graph.gexf' % q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tw_list = ('gilgul','data')\n",
    "\n",
    "wanted_users = set()\n",
    "friendships = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer = twitter_api.lists.members(slug=tw_list[1], owner_screen_name=tw_list[0])\n",
    "list_users = answer['users']\n",
    "\n",
    "print 'number of users:',len(list_users)\n",
    "print 'cursor:',answer['next_cursor']\n",
    "list_usernames = [u['screen_name'] for u in list_users]\n",
    "wanted_users = wanted_users.union(list_usernames)\n",
    "print json.dumps(list_usernames)\n",
    "print len(wanted_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'next cursor:',answer['next_cursor']\n",
    "print 'prev cursor:',answer['previous_cursor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer = twitter_api.lists.members(slug=tw_list[1], owner_screen_name=tw_list[0], cursor=answer['next_cursor'])\n",
    "list_users = answer['users']\n",
    "\n",
    "print 'number of users:',len(list_users)\n",
    "list_usernames = [u['screen_name'] for u in list_users]\n",
    "wanted_users = wanted_users.union(list_usernames)\n",
    "print json.dumps(list_usernames)\n",
    "print len(wanted_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'next cursor:',answer['next_cursor']\n",
    "print 'prev cursor:',answer['previous_cursor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "next_cursor = answer['next_cursor']\n",
    "\n",
    "while next_cursor>0:\n",
    "    answer = twitter_api.lists.members(slug=tw_list[1], owner_screen_name=tw_list[0], cursor=answer['next_cursor'])\n",
    "    list_usernames = [u['screen_name'] for u in answer['users']]\n",
    "    wanted_users = wanted_users.union(list_usernames)\n",
    "    print len(list_usernames)\n",
    "    print next_cursor\n",
    "    next_cursor = answer['next_cursor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(wanted_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_rate_limit(twitter_api, 'lists_memberships')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Graph - follow / following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used code and examples from Mining the Social Web, 2nd Edition - https://rawgit.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/master/ipynb/html/Chapter%201%20-%20Mining%20Twitter.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neat Link - https://github.com/lennerd/TwitterGraph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
