{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Data Analysis using Pandas DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic Passengers Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and... guess? upper-class.\n",
    "\n",
    "Now what we can learn from the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "path = '/class/itpmssd/datasets/titanic.csv'\n",
    "titanic = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pclass is a proxy for socio-economic status (SES)\n",
    " 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower\n",
    "\n",
    "sibsp           Number of Siblings/Spouses Aboard\n",
    "parch           Number of Parents/Children Aboard\n",
    "\n",
    "Sibling:  Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic\n",
    "Spouse:   Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored)\n",
    "Parent:   Mother or Father of Passenger Aboard Titanic\n",
    "Child:    Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic\n",
    "\n",
    "For a child who travelled with only a nanny, parch=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Percentile is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations fall. 25th percentile is the value below which 25 percent of the observations may be found.\n",
    "\n",
    "The value of the age distribution's median is at the 50% mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic.Age.hist(bins=25, figsize=(10,6))\n",
    "xlabel('age')\n",
    "ylabel('number of passengers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's group by Sex, and then see the differences in age\n",
    "grouped = titanic.groupby('Sex')\n",
    "grouped.Age.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped.Age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped.get_group('male').Age.hist(bins=20, figsize=(12,6), label=\"male\")\n",
    "grouped.get_group('female').Age.hist(bins=20, label=\"female\")\n",
    "legend()\n",
    "title(\"distribution of passengers by age/sex\")\n",
    "xlabel(\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(grouped.Age.get_group('male'), linewidth=2)\n",
    "figsize(10,4)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(grouped.Age.get_group('female'), linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Age: distribution plot - histogram + kde\n",
    "\n",
    "sns.distplot(titanic.Age.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_titanic = titanic.corr()\n",
    "corr_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up the matplotlib figure size\n",
    "plt.subplots(figsize=(12, 9))\n",
    "sns.corrplot(titanic)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- blue: positive correlation\n",
    "- red: negative correlation\n",
    "\n",
    "The darker the color, the stronger the correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From CSV File: Stop and Frisk / NYPD"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's try to grab data from a publicly available CSV file - the NYPD's Stop and Frisk dataset:\n",
    "- http://www.nyclu.org/files/stopandfrisk/Stop-and-Frisk-2012.zip\n",
    "\n",
    "Here's a description of what the dataset includes:\n",
    "- http://www.nyclu.org/files/SQF_Codebook.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's grab the csv file ('wget'), unzip it, and change its name to something that doesn't include spaces.\n",
    "# SSH into your remote machine and run the following commands:\n",
    "\n",
    "''' \n",
    "    cd /class/itpmssd/datasets\n",
    "    wget http://www.nyclu.org/files/stopandfrisk/Stop-and-Frisk-2012.zip\n",
    "    unzip Stop-and-Frisk-2012.zip\n",
    "    mv SQF\\ 2012.csv sf2012.csv\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Now let's explore the dataset using the command line first"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. How many rows in our dataset:\n",
    "    - \"cat sf2012.csv | wc -l\"\n",
    "\n",
    "\n",
    "2. What are the column names: (effectively the description of all variables)\n",
    "    - \"head -1 sf2012.csv\"\n",
    "\n",
    "(this dataset is WAY too big to fully load into our tiny little machine)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. 532k rows of data\n",
    "\n",
    "2. year,pct,ser_num,datestop,timestop,city,sex,race,dob,age,height,weight,haircolr,eyecolor,build,othfeatr,frisked,searched,contrabn,pistol,riflshot,asltweap,knifcuti,machgun,othrweap,arstmade,arstoffn,sumissue,sumoffen,crimsusp,detailcm,perobs,perstop,pf_hands,pf_wall,pf_grnd,pf_drwep,pf_ptwep,pf_baton,pf_hcuff,pf_pepsp,pf_other,cs_objcs,cs_descr,cs_casng,cs_lkout,cs_cloth,cs_drgtr,cs_furtv,cs_vcrim,cs_bulge,cs_other,rf_vcrim,rf_othsw,rf_attir,rf_vcact,rf_rfcmp,rf_verbl,rf_knowl,rf_furt,rf_bulg,sb_hdobj,sb_outln,sb_admis,sb_other,ac_proxm,ac_evasv,ac_assoc,ac_cgdir,ac_incid,ac_time,ac_stsnd,ac_other,forceuse,inout,trhsloc,premname,addrnum,stname,stinter,crossst,addrpct,sector,beat,post,xcoord,ycoord,typeofid,othpers,explnstp,repcmd,revcmd,offunif,offverb,officrid,offshld,ac_rept,ac_inves,radio,recstat,linecm\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's start by creating a smaller file -> take the first 100,000 rows from the original file:\n",
    "\n",
    "\"head -100000 sf2012.csv > sf2012_sm.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we can open the file\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "path = '/class/itpmssd/datasets/sf2012_sm.csv'\n",
    "df = pd.read_csv(path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# different ways to look at the data (since it is way too large to simply print)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[900:905]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The more you work with this dataset, and generally data writ large, the more you'll realize how messy it is. There will be empty fields, fields that don't really make sense, and they all will mess up your analysis process at some point. We have be constantly on the lookout for issues with our data, throughout our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# translate the messy date string into something cleaner -> a datetime structure\n",
    "# (M)MDDYYYY\n",
    "\n",
    "def parse_hour(timestop):\n",
    "    minute = timestop % 100\n",
    "    hour = timestop / 100\n",
    "    return hour,minute\n",
    "\n",
    "def parse_date(datestop):\n",
    "    month = int(str(datestop)[:-6])\n",
    "    day = int(str(datestop)[-6:-4])\n",
    "    year = int(str(datestop)[-4:])\n",
    "    return year, month, day\n",
    "\n",
    "def make_datetime(datestop, timestop):\n",
    "    year, month, day = parse_date(datestop)\n",
    "    hour, minute = parse_hour(timestop)\n",
    "    return datetime.datetime(year, month, day, hour)\n",
    "\n",
    "def make_date(datestop):\n",
    "    year, month, day = parse_date(datestop)\n",
    "    return datetime.datetime(year, month, day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print parse_date(df.ix[0].datestop)\n",
    "print parse_hour(df.ix[0].timestop)\n",
    "print make_datetime(df.ix[0].datestop, df.ix[0].timestop)\n",
    "print make_date(df.ix[0].datestop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now lets add a parsed datetime row in our data frame - by applying the function that we've just built\n",
    "# this will give us a 'dt' field we can use to group by\n",
    "\n",
    "df['dt']=df[['datestop','timestop']].apply(lambda x: make_datetime(x['datestop'], x['timestop']), axis=1)\n",
    "df['d']=df[['datestop']].apply(lambda x: make_date(x['datestop']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping: split-apply-combine"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "By \"group by\" we are referring to a process involving one or more of the following steps:\n",
    "\n",
    "- Split: the data into groups based on some criteria\n",
    "- Apply: a function to each group independently\n",
    "- Combine: the results into a new data structure\n",
    "\n",
    "In the case of our dataset, we'd like to group our data by day+hour and display the number of reported incidents over time, using hourly bins. What we'll need to do in order to make this happen:\n",
    "\n",
    "- Split the data by its index (the dt column)\n",
    "- Count the number of items in each group (number of incidents reported each day)\n",
    "- And bring this information back together into a new Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Grouping - counting the number of reported incidents per hour (can also do grouped.count())\n",
    "\n",
    "df.groupby(df.dt).size()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's make a plot - that shows trends over time\n",
    "%pylab inline\n",
    "\n",
    "df.groupby(df.dt).size().plot(figsize=(20,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we can easily specify a smaller date range\n",
    "df.groupby(df.dt).size()[:'2012-02-16'].plot(figsize=(20,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's examine age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apparently immortality is imminent\n",
    "sns.boxplot(df.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DRAAAAATS - more weirdnesses in the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# argmax prints the row # for the maximum value in a given column\n",
    "print 'maximum age index number:',df.age.argmax(),'\\n'\n",
    "\n",
    "# ix[] -> is a way to access values given a specific row\n",
    "print 'maximum age row:',df.ix[1021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How bad is it? How many rows in our data have weird age figures?\n",
    "\n",
    "print 'number of problematic rows:',len(df[[a>100 for a in df.age]])\n",
    "\n",
    "# 0.2% of our data is problematic\n",
    "len(df[[a>100 for a in df.age]])/float(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter out rows with faulty age info\n",
    "df = df[[x<100 for x in df.age]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's try this again\n",
    "sns.boxplot(df.age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we can always get rid of unnecessary columns - makes DataFrames easier to handle\n",
    "\n",
    "wanted_columns = ['dt','d','age','sex','race','height','weight','build','frisked']\n",
    "\n",
    "sm_df = df[wanted_columns]\n",
    "sm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's take a look at Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "race_labels = {\n",
    "    1:'black', \n",
    "    2:'black_Hispanic', \n",
    "    3:'white_Hispanic', \n",
    "    4:'white', \n",
    "    5:'Asian_Pacific_Islander', \n",
    "    6:'Am_Indian_Native_Alaskan'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sm_df.race[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we can use our handy dictionary to apply the labels\n",
    "[race_labels[x] for x in sm_df.race[10:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Handy way to count values in a column\n",
    "\n",
    "sm_df.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# histogram: show entries by race\n",
    "sm_df.race.hist(figsize=(12,6))\n",
    "ylabel('number of incidents')\n",
    "xlabel('race')\n",
    "title('incidents by race')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = sm_df.groupby('race')\n",
    "black = grouped.get_group(1)\n",
    "white_hispanic = grouped.get_group(3)\n",
    "white = grouped.get_group(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "black.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "grouped.get_group(1).hist(bins=30,figsize=(14,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot frisks broken down by race over time\n",
    "black.groupby('dt').frisked.size()[:'2012-02-16'].plot(figsize=(20,6), label='black')\n",
    "white_hispanic.groupby('dt').frisked.size()[:'2012-02-16'].plot(figsize=(20,6), label='white hispanic')\n",
    "white.groupby('dt').frisked.size()[:'2012-02-16'].plot(figsize=(20,6), label='white')\n",
    "legend()\n",
    "title('frisked over time, by race')\n",
    "ylabel('number of frisks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "black.groupby('d').size()[:'2012-02-16'].plot(kind=\"bar\", figsize=(20,6), label='black')\n",
    "white_hispanic.groupby('d').size()[:'2012-02-16'].plot(kind=\"bar\", color='red', figsize=(20,6), label='white_hispanic')\n",
    "white.groupby('d').size()[:'2012-02-16'].plot(kind=\"bar\", color='orange', figsize=(20,6), label='white')\n",
    "xticks(rotation=45)\n",
    "legend()\n",
    "title('daily incidents, by race')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "black.groupby(['d','frisked']).size()[:'2012-02-16'].unstack('frisked').plot(kind=\"bar\", figsize=(18,6))\n",
    "title('daily frisks, for race=black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sm_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(12, 10))\n",
    "sns.corrplot(sm_df, annot=False, diag_names=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle the small DataFrame (for when our system crashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the data for later\n",
    "import pickle\n",
    "\n",
    "f = open('/class/itpmssd/Week_2/sm_df.p','wb')\n",
    "pickle.dump(sm_df,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the data from pickled file\n",
    "\n",
    "pkl_file = open('/class/itpmssd/Week_2/sm_df.p','rb')\n",
    "sm_df = pickle.load(pkl_file)\n",
    "\n",
    "# ... aaand VOILA!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Smaller Stop-and-Frisk File/DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Smaller File -> so that we can look at longer term trends\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "columns = ['datestop','timestop','sex','race','age','height','weight','build','frisked']\n",
    "wanted_indices = set([3,4,6,7,9,10,11,14,16])\n",
    "\n",
    "columns = {\n",
    "    3:'datestop',\n",
    "    4:'timestop',\n",
    "    6:'sex',\n",
    "    7:'race',\n",
    "    9:'age',\n",
    "    10:'height',\n",
    "    11:'weight',\n",
    "    14:'build',\n",
    "    16:'frisked'\n",
    "}\n",
    "\n",
    "small_dict = {c:[] for c in columns.values()}\n",
    "\n",
    "cnt = 0\n",
    "with open(\"/class/itpmssd/datasets/sf2012.csv\",'rb') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        if cnt==0:\n",
    "            # dismiss the first row of the CSV file -> column headers\n",
    "            cnt += 1\n",
    "            continue\n",
    "        \n",
    "        # parse the date from the given string\n",
    "        cur_date = calc_datetime(row[3])\n",
    "        \n",
    "        for k,c in columns.items():\n",
    "            if c=='datestop':\n",
    "                small_dict[c].append(cur_date)\n",
    "            else:\n",
    "                if row[k]!='':\n",
    "                    # add relevant value to the dictionary\n",
    "                    small_dict[c].append(int(row[k]))\n",
    "                else:\n",
    "                    # add zeros where there's no data -> generally messes up our distribution estimation\n",
    "                    small_dict[c].append(0)\n",
    "        \n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sm_df = pd.DataFrame.from_dict(small_dict)\n",
    "sm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Kernel Density Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Kernel Density Estimate Plot -> KDE is a way to estimate the probability density function\n",
    "# default kernel is Gaussian\n",
    "\n",
    "sns.kdeplot(titanic.Age.dropna(), shade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pal = sns.blend_palette([sns.desaturate(\"royalblue\", 0), \"royalblue\"], 5)\n",
    "bws = [.1, .25, .5, 1, 2]\n",
    "\n",
    "# bw = bandwidth\n",
    "# lw = line width\n",
    "for bw, c in zip(bws, pal):\n",
    "    sns.kdeplot(titanic.Age.dropna(), bw=bw, color=c, lw=1.8, label=bw)\n",
    "\n",
    "plt.legend(title=\"kernel bandwidth\")\n",
    "sns.rugplot(titanic.Age.dropna(), color=\"#333333\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(grouped.get_group('male').Age.dropna(),label='male')\n",
    "sns.kdeplot(grouped.get_group('female').Age.dropna(),label='female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Violin Plot - effectively a box plot with a rotated kernel density plot on each side\n",
    "# in addition to showing what box plots show, they also present the probability density of the data at different values\n",
    "\n",
    "sns.violinplot(titanic.Age.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.violinplot(titanic.Age.dropna(), titanic.Sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related Reads and References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Precinct or Prejudice? understanding racial disparities in New York City's stop-and-frisk policy: https://5harad.com/papers/frisky.pdf\n",
    "\n",
    "- Kaggle competition (Titanic Dataset)\n",
    "http://nbviewer.ipython.org/github/agconti/kaggle-titanic/blob/master/Titanic.ipynb\n",
    "\n",
    "- Seaborn Plotting Library (w/some great examples)\n",
    "http://stanford.edu/~mwaskom/software/seaborn/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
